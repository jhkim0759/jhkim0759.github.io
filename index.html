<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jeonghwan's Web page</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <img class="profile-img" src="assets/profile.jpg" alt="논문 이미지">
            <h1>Jeonghwan Kim</h1>
            <p class="subtitle">AI Researcher / Ph.D Student@NTU</p>
            
            <div class="social-links">
                <a href="mailto:kimj0010@e.ntu.edu.sg" class="social-link">E-mail</a>
                <a href="https://drive.google.com/file/d/1NpvUTjYbYuD4hrwgKUAsEc0aSRABB_dJ/view?usp=drive_link" class="social-link">CV</a>
                <a href="https://scholar.google.com/citations?user=TKvOvEwAAAAJ&hl=ko" class="social-link">Google Scholar</a>
                <a href="https://github.com/jhkim0759" class="social-link">GitHub</a>
                <a href="https://www.linkedin.com/in/jhkim0759/" class="social-link">LinkedIn</a>
            </div>
        </header>

        <div class="content">
            <section class="section">
                <p class="about-text">
                    I'm a PhD student at MMLab at Nanyang Technological University (NTU) advised by Prof. Xingang Pan. I completed my Master's Degree in Artificial Intelligence at Konkuk University, advised by Prof. Wonjun Kim. Throughout my master's program, I primarily explored 3D Vision tasks, particularly those involving humans and diverse computer vision tasks. While serving as a research engineer at Spocklabs, I specialized in low-level vision tasks such as Video Frame Interpolation and Super Resolution. 
                </p>
            </section>
            <section class="section">
                <h2>Publication</h2>
                <div class="paper-list">
                    <div class="paper-item" OnClick="location.href='https://arxiv.org/abs/2304.09502'" style="cursor:pointer;">
                        <div class="paper-image">
                            <!-- 실제 논문 이미지로 교체하세요: <img src="assets/ " alt="논문 이미지"> -->
                            <div class="paper-placeholder">🧠</div>
                        </div>
                        <div class="paper-content">
                            <div class="paper-year">2025</div>
                            <div class="paper-title">FastMesh: Efficient Artistic Mesh Generation via <br> Component Decoupling</div>
                            <div class="paper-authors"><strong>J. Kim</strong>, Y. Lan, A. Fortes, Y. Chen, X. Pan. </div>
                            <div class="paper-venue">arXiv</div>
                            <div class="paper-links">
                                <a href="projects/FastMesh/index.html" class="paper-link primary">Project Page</a>
                                <a href="https://arxiv.org/abs/2304.09502" class="paper-link">arXiv</a>
                                <a href="https://github.com/jhkim0759/FastMesh" class="paper-link">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="paper-item" OnClick="location.href='https://arxiv.org/abs/2304.09502'" style="cursor:pointer;">
                        <div class="paper-image">
                            <!-- 실제 논문 이미지로 교체하세요: <img src="your-paper-image.jpg" alt="논문 이미지"> -->
                            <!-- <div class="paper-placeholder">🧠</div> -->
                            <img src="assets/PointHMR.png" alt="PointHMR">
                        </div>
                        <div class="paper-content">
                            <div class="paper-year">2023</div>
                            <div class="paper-title">Sampling is Matter: Point-guided 3D Human Mesh Reconstruction </div>
                            <div class="paper-authors"><strong>J. Kim*</strong>, M. Gwon*, H. Park, H. Kwon, G. Um, W. Kim. </div>
                            <div class="paper-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</div>
                            <div class="paper-links">
                                
                                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Sampling_Is_Matter_Point-Guided_3D_Human_Mesh_Reconstruction_CVPR_2023_paper.pdf" class="paper-link primary">Paper</a>
                                <a href="https://arxiv.org/abs/2304.09502" class="paper-link">arXiv</a>
                                <a href="https://github.com/DCVL-3D/PointHMR_release" class="paper-link">Code</a>
                                
                            </div>
                        </div>
                    </div>

                    <div class="paper-item" OnClick="location.href='https://link.springer.com/article/10.1007/s00530-023-01216-5'" style="cursor:pointer;">
                        <div class="paper-image">
                            <!-- 실제 논문 이미지로 교체하세요: <img src="your-paper-image.jpg" alt="논문 이미지"> -->
                            <img src="assets/Lapformer.jpg" alt="PointHMR">
                        </div>
                        <div class="paper-content">
                            <div class="paper-year">2024</div>
                            <div class="paper-title">Learning Scale-aware Relationships via Laplacian Decomposition-based Transformer for 3D Human Pose Estimation</div>
                            <div class="paper-authors"><strong>J. Kim</strong>, H. Kwon, S. Y. Lim, W. Kim. </div>
                            <div class="paper-venue">Multimedia Systems, vol. 30, Jan., 2024</div>
                            <div class="paper-links">
                                <a href="https://link.springer.com/article/10.1007/s00530-023-01216-5" class="paper-link primary">Paper</a>
                                <a href="https://github.com/DCVL-3D/Laphormer_release" class="paper-link">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="paper-item" OnClick="location.href='https://www.sciencedirect.com/science/article/abs/pii/S1047320323001311'" style="cursor:pointer;">
                        <div class="paper-image">
                            <!-- 실제 논문 이미지로 교체하세요: <img src="your-paper-image.jpg" alt="논문 이미지"> -->
                            <img src="assets/pkcn.png" alt="PointHMR">
                        </div>
                        <div class="paper-content">
                            <div class="paper-year">2023</div>
                            <div class="paper-title">Part-attentive Kinematic Chain-based Regressor for 3D Human Modeling</div>
                            <div class="paper-authors"><strong>J. Kim</strong>, G. Um, J. Seo, W. Kim.  </div>
                            <div class="paper-venue">Journal of Visual Communication and Image Representation, vol. 95, Sep., 2023</div>
                            <div class="paper-links">
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320323001311" class="paper-link primary">Paper</a>
                                <a href="https://github.com/DCVL-3D/PKCN_release" class="paper-link">Code</a>
                            </div>
                        </div>
                    </div>


                
            <section class="section">
                <h2>Reviewer Services</h2>
                <div class="reviewer-services">
                    <strong class="reviewer-item">
                        <div class="reviewer-title">ACM SIGGRAPH Asia 2025</div>
                        <div class="reviewer-title">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</div>
                        <div class="reviewer-title">The Journal of Supercomputing</div>
                        <div class="reviewer-title">IEEE Transactions on Information Forensics and Security (T-IFS)</div>
                    </strong>
                </div>
            </section>
            
            <section class="section">
                <h2>Research Experience</h2>
                <div class="projects-grid">
                    <div class="project-card">
                        <h3>Spocklabs, Research engineer</h3>
                        <p>Research on Video Frame Interpolation and Video Super Resolution</p>
                    </div>
                    <div class="project-card">
                        <h3>Electronics and Telecommunications Research Institute (ETRI)</h3>
                        <p>A Study on 3D Information Acquisition Technology for Producing Volumetric Images</p>
                    </div>
                    <div class="project-card">
                        <h3>National Research Foundation of Korea (NRF)</h3>
                        <p>High-Performance Method for Image Enhancement via Deep Neural Network on Mobile Devices</p>
                    </div>
                    <div class="project-card">
                        <h3>Korea Institute of Science and Technology Information (KISTI)</h3>
                        <p>Development of Deep Learning-Based Image Restoration Technology</p>
                    </div>
                    <div class="project-card">
                        <h3>N Tech Service, Intern</h3>
                        <p>Trained in JAVA Spring-based web development techniques and learned how to write collaborative and comprehensible codes</p>
                    </div>
                </div>
            </section>
            <!-- <section class="section">
                <h2>Research Experience</h2>
                <div class="skills-grid">
                    <div class="skill-card">
                        <h3>SpockLab</h3>
                        <p>TensorFlow, PyTorch<br>Scikit-learn, Keras</p>
                    </div>
                    <div class="skill-card">
                        <h3>ETRI</h3>
                        <p>BERT, GPT, Transformer<br>NLTK, spaCy, Hugging Face</p>
                    </div>
                    <div class="skill-card">
                        <h3></h3>
                        <p>OpenCV, YOLO<br>CNN, Image Classification</p>
                    </div>
                </div>
            </section> -->

        <footer>
            <p>&copy; 2025 Jeonghwan Kim. All rights reserved.</p>
        </footer>
    </div>

    <script>
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth'
                    });
                }
            });
        });

        document.querySelector('.contact-form').addEventListener('submit', function(e) {
            e.preventDefault();
            alert('메시지가 전송되었습니다! (실제로는 백엔드 서버가 필요합니다)');
        });

        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver(function(entries) {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        document.querySelectorAll('.skill-card, .project-card, .paper-item').forEach(el => {
            el.style.opacity = '0';
            el.style.transform = 'translateY(20px)';
            el.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(el);
        });
    </script>
</body>
</html>